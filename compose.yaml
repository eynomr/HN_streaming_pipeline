version: '3.8'

services:
  zookeeper:
    image: bitnami/zookeeper:3.9.2
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    networks:
      - hn_stream_network
    environment:
      ALLOW_ANONYMOUS_LOGIN: "yes"
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    healthcheck:
      test: ['CMD', 'bash', '-c', "echo 'ruok' | nc localhost 2181"]
      interval: 10s
      timeout: 5s
      retries: 3

  kafka:
    image: bitnami/kafka:3.7.0
    hostname: kafka
    container_name: kafka
    ports:
      - "9092:9092"
      - "9101:9101"
    networks:
      - hn_stream_network
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      KAFKA_CFG_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_CFG_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_CFG_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_CFG_BOOTSTRAP_SERVERS: PLAINTEXT://kafka:29092
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
    healthcheck:
      test: [ "CMD", "bash", "-c", 'nc -z localhost 9092' ]
      interval: 10s
      timeout: 5s
      retries: 3

  kafdrop:
    image: obsidiandynamics/kafdrop
    platform: "linux/amd64"
    hostname: kafdrop
    container_name: kafdrop
    ports:
      - "9000:9000"
    networks:
      - hn_stream_network
    environment:
      KAFKA_BROKERCONNECT: "kafka:29092"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000"]
      interval: 10s
      timeout: 5s
      retries: 3
    depends_on:
      kafka:
        condition: service_healthy

  airflow:
    image: apache/airflow:slim-2.9.0-python3.9
    platform: "linux/amd64"
    command: webserver
    entrypoint: ["/bin/bash", "/opt/airflow/scripts/airflow-entrypoint.sh"]
    depends_on:
      - postgres
    ports:
      - "8080:8080"
    environment:
      - LOAD_EX=n
      - EXECUTOR=Sequential
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      - AIRFLOW_WEBSERVER_SECRET_KEY=extremly_secret_key
    logging:
      options:
        max-size: "10m"
        max-file: "3"
    volumes:
      - ./src/dags:/opt/airflow/dags
      - ./scripts/airflow-entrypoint.sh:/opt/airflow/scripts/airflow-entrypoint.sh
      - ./requirements.txt:/opt/airflow/requirements.txt
    healthcheck:
      test: ['CMD-SHELL', "[ -f /opt/airflow/airflow-webserver.pid ]"]
      interval: 10s
      timeout: 5s
      retries: 3
    networks:
      - hn_stream_network

  postgres:
    image: postgres:13
    platform: "linux/amd64"
    container_name: postgres
    ports:
      - "5432:5432"
    networks:
      - hn_stream_network
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 10s
      timeout: 5s
      retries: 3

  airflow_scheduler:
    image: apache/airflow:slim-2.9.0-python3.9
    platform: "linux/amd64"
    depends_on:
      airflow:
        condition: service_healthy
    environment:
      - LOAD_EX=n
      - EXECUTOR=Sequential
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      - AIRFLOW_WEBSERVER_SECRET_KEY=extremly_secret_key
    volumes:
      - ./src/dags:/opt/airflow/dags
      - ./scripts/airflow-entrypoint.sh:/opt/airflow/scripts/airflow-entrypoint.sh
      - ./requirements.txt:/opt/airflow/requirements.txt
    command: bash -c "pip install -r ./requirements.txt && airflow db upgrade && airflow scheduler"
    networks:
      - hn_stream_network


networks:
  hn_stream_network: